{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f339562c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3968718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf41da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\lenovo\\\\OneDrive\\\\Documents\\\\datasets_4123_6408_framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5278fcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bc04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2354bd",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31eba2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bbf6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fa7ca",
   "metadata": {},
   "source": [
    "# Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "962e496e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3964095939.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[37], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    bin_cols = [\"male\", \"currentSmoker\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\"z,]\u001b[0m\n\u001b[1;37m                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the binary columns\n",
    "bin_cols = [\"male\", \"currentSmoker\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\"z,]\n",
    "\n",
    "# Fill missing values for binary features with the most frequent value (mode)\n",
    "for col in bin_cols:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0de8c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_14876\\508612170.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Fill missing values for numeric features\n",
    "numeric_cols = [\"cigsPerDay\", \"BPMeds\", \"totChol\", \"BMI\", \"heartRate\", \"glucose\"]\n",
    "for col in numeric_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7cf12",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c06bb283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1     644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "582bf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['TenYearCHD'] == 0]\n",
    "df_minority = df[df['TenYearCHD'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # To match majority class\n",
    "                                 random_state=42) # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037d59a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3596\n",
       "1    3596\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbf299",
   "metadata": {},
   "source": [
    "# Train Test Split and Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "845d95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_balanced.drop(columns=['TenYearCHD'])\n",
    "y = df_balanced['TenYearCHD']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6809b",
   "metadata": {},
   "source": [
    "# Scaling (StandardScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9cd6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dcb35",
   "metadata": {},
   "source": [
    "# Training 10 Models With Different Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcd75f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianNB\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{clf_name} Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"Classification Report for {clf_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(f\"Confusion Matrix for {clf_name}:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c01d4",
   "metadata": {},
   "source": [
    "# Show Each Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9abac10f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianNB\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define a list of classifiers\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'F1-Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    \n",
    "    # Append results to DataFrame\n",
    "    results_df = results_df.append({'Model': clf_name, 'Accuracy': accuracy, 'F1-Score': f1_score, \n",
    "                                    'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c700a81",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c4c4059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9728978457261988\n",
      "Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       735\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[701  34]\n",
      " [  5 699]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report for Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf32e7",
   "metadata": {},
   "source": [
    "# Single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "886f167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  0\n",
      "actual class  0\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db84a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[200].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89241591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 3:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[110].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc436e93",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3892cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_classifier,open(\"C:\\\\Users\\\\lenovo\\\\OneDrive\\\\Documents\\\\rf_classifier.pkl\",'wb'))\n",
    "pickle.dump(scaler,open(\"C:\\\\Users\\\\lenovo\\\\OneDrive\\\\Documents\\\\scaler.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96693443",
   "metadata": {},
   "source": [
    "# Load models to test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fc964d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the RandomForestClassifier model\n",
    "with open(\"C:\\\\Users\\\\lenovo\\\\OneDrive\\\\Documents\\\\rf_classifier.pkl\", \"rb\") as file:\n",
    "    rf_classifier = pickle.load(file)\n",
    "\n",
    "# Load the scaler\n",
    "with open(\"C:\\\\Users\\\\lenovo\\\\OneDrive\\\\Documents\\\\scaler.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19320175",
   "metadata": {},
   "source": [
    "# Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03d110d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(model, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose):\n",
    "    # Encode categorical variables\n",
    "    male_encoded = 1 if male.lower() == \"male\" else 0\n",
    "    currentSmoker_encoded = 1 if currentSmoker.lower() == \"yes\" else 0\n",
    "    BPMeds_encoded = 1 if BPMeds.lower() == \"yes\" else 0\n",
    "    prevalentStroke_encoded = 1 if prevalentStroke.lower() == \"yes\" else 0\n",
    "    prevalentHyp_encoded = 1 if prevalentHyp.lower() == \"yes\" else 0\n",
    "    diabetes_encoded = 1 if diabetes.lower() == \"yes\" else 0\n",
    "    \n",
    "    # Prepare features array\n",
    "    features = np.array([[male_encoded, age, currentSmoker_encoded, cigsPerDay, BPMeds_encoded, prevalentStroke_encoded, prevalentHyp_encoded, diabetes_encoded, totChol, sysBP, diaBP, BMI, heartRate, glucose]])\n",
    "    \n",
    "    # scalling\n",
    "    scaled_features = scaler.transform(features)\n",
    "    \n",
    "    # predict by model\n",
    "    result = model.predict(scaled_features)\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e3e5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patiennt has No Heart Deseas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "male = \"female\"\n",
    "age = 56.00\n",
    "currentSmoker = \"yes\"\n",
    "cigsPerDay = 3.00\n",
    "BPMeds = \"no\"\n",
    "prevalentStroke = \"no\"\n",
    "prevalentHyp = \"yes\"\n",
    "diabetes = 'no'\n",
    "totChol = 285.00\n",
    "sysBP = 145.00\n",
    "diaBP = 100.00\n",
    "BMI = 30.14\n",
    "heartRate = 80.00\n",
    "glucose = 86.00\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Diseas\")\n",
    "else: \n",
    "    print(\"The Patiennt has No Heart Deseas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7bfbe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patient has Heart Diseas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "male = 'female'\n",
    "age = 63.0\n",
    "currentSmoker = 'yes'\n",
    "cigsPerDay = 3.0\n",
    "BPMeds = 'no'\n",
    "prevalentStroke = 'no'\n",
    "prevalentHyp = 'yes'\n",
    "diabetes = 'no'\n",
    "totChol = 267.0\n",
    "sysBP = 156.5\n",
    "diaBP = 92.5\n",
    "BMI = 27.1\n",
    "heartRate = 60.0\n",
    "glucose = 79.0\n",
    "result = 1.0\n",
    "\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Diseas\")\n",
    "else: \n",
    "    print(\"The Patiennt has No Heart Deseas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a8bf98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131dba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
